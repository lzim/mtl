## Session 07 Say Guide

[<img src = "https://github.com/lzim/teampsd/blob/master/resources/title_slides/mtl_s07_base_case_title.png"
     height = "175" width = "420">](#DontLink)  

**MTL Live Session 07**

**Today we're modeling to learn how to evaluate our Base Case of no new decisions.**

Hello! I'm \________________ (facilitator's name) and I'm \_______________ (co-facilitator's name). Today we're modeling to learn how to evaluate our Base Case of no new decisions.

**Start with a review of what was learned in the last session and what we will do during the session today:**

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "30" width = "30" style ="display: inline-block"/>](#.) 00:00-00:10 | **Review** progress to date and learning objectives for this session | **Practice describing specific learning/skills developed last session and confirm consensus on team's highest priority need.**

<!-- Do/Done Tables -->
| [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/done.png" height = "80" width = "80">](#.) **Done** | [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/do.png" height = "90" width = "90">](#.) **Do** |
| --- | --- |
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We logged in to our individual world at mtl.how/sim. We used the question we entered during the previous session and added our own hypothesis about the Base Case (bc) run in the Text section. | [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We will run a "BC" simulation and review the impact of making no new decisions on ___________ [the variables relevant to the team's question] in the _MTL_ sim UI Outputs section.|

**After this session you’ll be able to:**

<!-- Learning Objectives Icon -->
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/learning_objectives.png" height = "90" width = "90" style ="display: inline-block"/>](#.)

**Learning Objectives**

1. Describe the base case of no new decisions in your team.

2. Test out your thinking about what is likely to cause oscillation in team trends.

3. Apply systems thinking to develop a hypothesis about your team's clinical priority.

**After this review, pass control over to the team.  Ask the Team Lead to log into the SimUI, join the current session, and share their screen.**

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "30" width = "30" style ="display: inline-block"/>](#.) 00:10-00:20 | **Cue** up the team's question from Session 5 and hypothesis from Session 6 **Review** the team data that supports the team's question and the systems story that supports the team's hypothesis. | **Practice highlighting specific values from the Team Data table and variables from the complexity reveal (causal loop) that are guiding the in-session work to address the team's highest priority need.**

**In-session Exercise (30 minutes)**

**Running a Base Case**

**1. Log in to your team world at mtl.how/sim.**

- During the time it takes the team lead to start screen share and navigate to the sim, present the purpose of the exercise:

- The purpose for this activity is to test the hypothesis you developed in the last session.

By the end, the team should be able to run an experiment in the SimUI, explore results, and be able to explain the systems causes that generated those results.

**2. Join Current Session to pick up where the team left off.**

**3. Orient yourself to the main page: Team Name (when you're in your individual world, the team name is your name); selected module (CC, MM, PSY, AGG, or SP); selected data file. All slider settings in the Experiments section are at Base Case or default values.**

- "In the last session, you all created a question about your team's top improvement priority and the Systems Story that surrounds that issue.  Today we're going to make that story come alive -- we are going to run a simulation, and see the impact of these system causes over the next two years, as as function of our local capacities and constrains, as estimated with our local data.  The first step in learning from simulation is to run a base case or “status quo” simulation against which all future experiments will be compared.  Last time, you hypothesized that \_____________ (include specific variables, loops, data)."

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/illustrations/data_ui_sim_ui.png">](#.)

- Now, in the window floating on the right side of the screen, **add** to the team's question about the Base Case in the *Our Question* text box. Here you'll briefly describe what your team wants to learn from this experiment of no new decisions.

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_question.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Example Question to add:** What happens to ______________ (from the team's priority) if we make no new decisions?

- There is important research showing that is not likely to improve learning to click around and run experiments without stating what you *expect* will happen over the next two years before you run the simulation.

- In order to benefit from experiential simulation learning, you need to create a hypothesis -- an if/then statement about what you believe will happen over the next two years as a consequence of your change. Through this process you can be surprised, have some things confirmed, but perhaps also find that when more variables and complexity are accounted for, there may be counter-intuitive findings too.

**4. Expand the Outputs and Text section and enter text in the boxes to reflect your question and hypothesis about a base case run – one where no new decisions are made in your team, and run the simulation out to its 2-year end just using data pulled in from your team data file.**

- **Add** your hypothesis about the base case run results in the *Our Hypothesis* text box. Reference team data value relevant to the team's question. We want to be as specific as possible, and we have the question, hypothesis, findings and decisions boxes here, which the teams can use as a lab notebook to track their thinking. They can then save their work, so that they can efficiently pick up where they left off, which is critical when time for team huddles in the clinic is very tight.

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_hypothesis.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Example Hypotheses to add:** *Outline the systems story your team believes will cause the outcomes your team expects to observe.*

**-- Module specific Hypotheses, Findings, and Decisions are included in a table below --**

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "30" width = "30" style ="display: inline-block"/>](#.) 00:20-00:25 | **Run** a simulation and save results | **Ask the team lead to narrate this process.**

- Helpful tip: To run the Base Case, let’s first make sure that all the Experiment sliders are indeed set for the Base Case. When you look in the Experiments section, you should see that the box next to each slider says either zero or bc. If it says bc, it means the value the model will run is the number from the Team Data Table. A few sliders have a different setting. If you see a purple Sensitivity slider, it will start at a default value of 1, which is the mid-range, between no relationship between those two variables, and a very strong relationship. (And if there’s a Team Data vs Balanced switch, Balanced will be the default setting.)

**5. Run, then Save (without resetting) the run with the name Base Case.**

- Once we’ve verified that sliders are set for the Base Case and we’ve entered our question and hypothesis, we’re ready to hit **Run**. (drum roll!)

- Now let’s open the Outputs section and see what we find. The quick way to do this is to click the "expand" button in the blue bar of the Texts section.

- This opens the full Outputs and Text section, which now shows all the Text boxes and a larger Results Dashboard where you can see several charts at once, and a Control Panel on the left.

**Before we go further, it’s a good time to go ahead and Save this run.**

- Saving without Resetting will capture the text that we’ve written in the boxes and the settings and results of our run. We’ll still be able to enter more text to finish our consideration of this test as long as we don’t re-set the sim.

- So, click on *Save* at the top and then click *Yes*. This warning is just a reminder of how important it is to record your thinking in the Text boxes so your learning from what you’ve done doesn’t evaporate.

- The Save menu helps you enter a name for each run based on what sliders you moved. In this case, it’s the Base Case, so on the Variable drop-down menu just select Base Case and click *Add*.

- You’ll see “bc” entered in the Experiment Name field and now you can click *Save* again in the top right.

- **Caution**: Only choose the *Save and Reset* button at the bottom when you’re finished recording all you need to in the Text section. Or you can choose *Discard* if you weren’t ready to save or name the run.

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "30" width = "30" style ="display: inline-block"/>](#.) 00:25-00:40 | **Describe** findings/decisions and saving | **Practice describing specific output charts (system behaviors) you're going to check and discuss as a team in relation to their team's highest priority need.**

**6. Review the Current Experiment Values in the Control Panel: You should see all variables at base case or default values.**

- This is where you can remind yourself of the settings for the current experiment or check to make sure they are what you meant to set.

**7. Orient yourself to the charts in the Results Dashboard (axes, units, legend, drop-down menu options).**

- Now let’s look at the Results. Notice that each chart has a title below it and a drop-down menu. You have a wide selection of variables to choose from to look at results. The units are shown inside the chart at the top left – usually Weeks, Patients, Appointments, or a Percent, or a rate like Patients per Week.

- The axes adjust dynamically – so even if the units of two side-by-side charts are the same, you have to check the scale before comparing them visually.

**8. Describe what you see in the *Our Findings* textbox. What do you notice about the results for ________ [relevant to the team's question]? Do they match your hypothesis? Compare the values in the charts with the Team Data Table numbers.**

**9. Record your Findings - what you learned from the Results compared to your Hypothesis.**

- Add to the *Our Findings* text box your explanation for why the results do or do not conform to your hypothesis.

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_findings.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Example Findings:** *Describe your team's findings, insights and conclusions from this experiment.*

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "30" width = "30" style ="display: inline-block"/>](#.) 00:40-00:50 | **Come to consensus** on the next experiment | **Practice guiding the team to the highest leverage experiments (changes that will impact the most patients) that represent actions they could take today.**

**10. In Our Decisions, record what these findings suggest doing differently in your team. Also write down what the team decided to investigate next.**

- Now that we have an experiment to compare against, what changes do you want to test next? What is the first improvement idea you want to try as a team? Record this next step in the *Our Decisions* textbox.

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_decisions.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Example Decisions:** *Based on what you learned in this experiment, what changes are you ready to make in your practice?*  

**11. Save and Reset when ready. Notice that the sim UI automatically adds the date to the name of the run for you. Remember to log off before you exit the browser window.**

**That’s it for _Modeling to Learn_ how to evaluate the Base Case of no new decisions. Next is our Done/Do review.**

- Today we entered our Question, Hypothesis, Findings and Decisions for our base case run in the Text section. Before next time, please log in to mtl.how/sim and explore the results of the base case run in the Results Dashboard found in the Outputs and Text expanded view.

**Done and Do (15 minutes)**

<!-- Do/Done Tables -->
| [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/done.png" height = "80" width = "80">](#.) **Done** | [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/do.png" height = "90" width = "90">](#.) **Do** |
| --- | --- |
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We entered our Question, Hypothesis, Findings and Decisions for our Base Case (bc) run in the Outputs and Text section. | [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) Log in to mtl.how/sim and explore the results of the bc run in the Results Dashboard of the Outputs and Text section to prepare for experiment 1. |

**DO Demo**

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "30" width = "30" style ="display: inline-block"/>](#.) 00:50-00:60 | **Success** - A successful Done/Do Review is short, specific, simple and shown.

1. Log back into the SIM UI, choose "Team world," and "Join Current Experiment."
2. In the Experiments, select your bc run from the list of previous experiments. Click on GO check the box to include text. This will reload your prior QUESTION, HYPOTHESIS, FINDINGS and DECISIONS.
3. Expand the *Outputs and Text* section (two clicks!) to reveal all the results and findings saved from the run. Review what you learned and what the team decided to try for Experiment 1. What is the question you want to answer with this experiment? What is your hypothesis about the results?
4. Log out.

**Until next time, thank you for *Modeling to Learn*!**

***Base Case Dynamics for each module***

|**Module** | Example Text|
|--------:|:---------|
| **CC & MM**| Hypothesis: |
|| If we make no new decisions then patients will start accumulating in "the waiting room" for care coordination. But then it will swing back the other way, and at some point the wait time will become steady at about the level it is now. This is because of the balancing that happens between using appointments for new and existing patients. The number of patients in care will stay constant. |
||If we make no new decisions then we will reach the same proportion of our patients with medication assisted therapy for OUD.|
|| Findings: |
|| All variables will show no change over the next two years.  Without any new decisions, the team will continue to experience their historically "normal" behavior.   These flat lines could be seen as favorable, or not, depending on the team's expectations.  Example: "We can see our Return-to-clinic Visit Interval (RVI) in the base case is the same for all patient needs, but we'd like to better meet more specific needs of patients evidence-based pharmacotherapy (EBPharm)."
|| Note: If team has prioritized data on "Existing Patient Return-to-Clinic Visit Interval," then the RVI used by the team will match the estimate calculated from their patients' data, but start rate generated by the model will not.  If the start rate is higher than the estimate, then this implies that the team is actually working more efficiently (fewer missed appointments, shorter engagement durations, etc.) than we can see from the data or perhaps the 75th percentile we're using to estimate their appointment supply is too conservative.  If the start rate is lower than the data suggest, then the team could be facing more hurdles than we can see in the data, are seeing patients for longer, or perhaps the 75th percentile we're using to estimate their appointment supply is too optimistic.  |
||Note: If team has prioritized data on "New Patient Start Rate," then the start rate shown in the base case will match the estimate calculated from their patients' data, but the RVI used by the team will not.  If the RVI used by the team in the simulation is more frequent than the estimate, then this implies that the virtual team is either more efficient, has more capacity, fewer no-shows, or shorter engagement durations (or some combination) than the real-world team.  If the RVI used by the virtual team is slower than the real team, then the opposite is true -- that the real-world team is more efficient, has more capacity, fewer no-shows, or shorter engagement durations (or some combination) than we can see from their data.|
|| Decisions: |
|| Next time we will experiment with increasing our appointment supply by 5 appt/wk to attempt to reduce New Patient Wait Times.|
||Next time we will experiment with increasing both our referrals to DEP and increasing those patients' RVI to attempt to reduce our DEP wait times.|
| **PSY**| Hypothesis: |
|| If we make no new decisions then we expect that we will continue to see fewer Psy and EBPsy patients than we want because we aren't graduating our psychotherapy patients. We hypothesis that the number of patients receiving an evidence-based dose of PSY is currently low, taking into consideration that Completers who Graduate is about 4% and that Initiators who Complete is just 37%.
|| Findings:|
||All variables will show no change over the next two years.  Without any new decisions, the team will continue to experience their historically "normal" behavior.   These flat lines could be seen as favorable, or not, depending on the team's expectations.  Example: Our team will continue to start ~3ppw, with the majority of our slots going to patients who have been in care after their first 3 months. Our completion rate will remain high (at 0.5 ppw), but our graduation rate will not improve, remaining at 0.04 implementation ppw (or one patient every 6 months). |
||If the team is interested in how their supply is being used (the number of slots used by patients in their first 3 months, vs after), then the Sankey chart can reveal details on how many slots are currently used in each care pathways.  Example: Based on the Sankey diagram, we understand that out of N=371 patients who have one PSY visit, n=289 are Initiators. Of these, only n=107 are Completers, and of Completers, on n=4 graduate after having an evidence-based dose of PSY (about 8 sessions in their first three months with the team). Patients who remain in care after their first three months take up the majority of slots, with patients who only get one visit in their first 3 months eventually taking 6 more visits before ending (thus never receiving a complete dose), and patients who complete but return taking 26 visits before ending (double the evidence base).|
||Decisions:|
||We can do much better. We can start by trying to increase the percentage of Completers who graduate, from 3.77% to as high as 75%.  This will reduce the number of appointment slots used by patients who continue therapy after already receiving a complete dose, hopefully opening up more slots to new patients.|
| **AGG**| Hypothesis: |
||If we make no new decisions, then, based on our team data, we expect to see that the majority of our patients will continue to receive MM. By far our MM and PSY patients have the longest engagement time and account for more than 40% of our services. Patients will continue to accumulate while waiting for care.|
||Findings:|
||Using the compare services features, our hypothesis is supported. Our baseline shows that we have more than 1000 MM patients in service, followed by PSY (about 300 patients), CC (about 260 patients), and by Adjunct (about 175 patients). Interestingly, patients receiving group services drops to  about 100 patients at about 1.5 years into the experiment.  Include dynamics = oscillations in xxxx caused by  feedback loop...Drop in yyyy caused by |
||Decisions: |
||Ideally, we would like to reduce the median engagement time for both MM and PSY, as patients are receiving treatment time that is longer than recommended for PSY and the return visit interval time for PSY is also long (17 weeks between visits on average!). Reducing the engagement time should free up supply, while decreasing the RVI (i.e., meeting more frequently) should increase the slots used by our PSY patients.  We hope to explore the trade-off between these two clinical decisions on our whole panel, and the ability to start new patients in PSY).|
|**SP**|Hypothesis:|
||If we make no new decisions, then we expect to see no changes in care quality, performance, or wait times in all three settings – all the current historical averages for patients in care, step down rates, etc. will hold for the next two years. Patient risk will not improve.|
||Findings: |
||Since the teams in the simulation experience no external shocks and make no new decisions, the historical rates all continue for the next two years. We will still have about 4 patients with a high risk flag, and, if we click on the plus sign in the upper right corner of the "GMH to SMH Recommend Step up Rate" box and zoom out to see how our team is working with the rest of the Mental Health continuum, we see that we will continue to have about 57 high-symptom patients who are waiting to step up to Specialty Mental Health. If we look over to the Team Data Table, we can see that these patients are waiting an average of 28 weeks before starting treatment there. Now, if we minimize the table [CLICK ON THE RED ARROW] and open up "GMH Patients and Patients Waiting to Start," we can see how many patients total are in care. Click on the "BC" button in "Manageable Total Patients" to see that we have 517 patients in care.  Care quality does not improve (specifically, the team's main concern of wait time to step up). However, if our manageable patient load stays the same over the next two years at the past two years, we shouldn’t expect things to get worse, either.|
||Decisions:|
||Given the high wait times to step to other settings and how hard it will be to reduce these wait times directly by working with leadership and the other teams, we should explore the effects of something that would be easier to implement - shift to using measurement-based care for all patients in our team - to see what both the positive and unexpected impacts will be.  We expect that we will be able to both develop treatment plans faster and improve patients symptoms faster if we continually track their symptoms, hopefully engaging the "Higher Care Quality Improves Recovery" cycle.|
