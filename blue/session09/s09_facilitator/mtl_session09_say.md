---
title: "MTL Session 9 - Facilitator Say"
author: "Team PSD"
date: "March 2020"
release: "MTL 3.0"
output: 
  github_document: default
  html_document: default
  pdf_document: default
  word_document: default
  ioslides_presentation: default
  slidy_presentation: default
  powerpoint_presentation: default
---

[<img src = "https://github.com/lzim/teampsd/blob/master/resources/title_slides/mtl_s09_compare_alternatives_title.png"
     height = "175" width = "420">](#DontLink)

# MTL Live Session 09

## Today we're modeling to learn how to compare alternatives.

Hello! I'm \________________ (facilitator's name) and I'm \_______________ (co-facilitator's name). Today we're modeling to learn how to compare alternatives.

**As you can see in the Done/Do table of the Learner See Guide:**  

## Done and Do (15 minutes)

<!-- Do/Done Tables -->
| [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/done.png" height = "80" width = "80">](#.) **Done** | [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/do.png" height = "90" width = "90">](#.) **Do** |
| --- | --- |
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We explored the Base Case (bc) and experiment 1 and drafted a dynamic hypothesis to prepare for experiment 2.| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We will run experiment 2 to compare alternatives.|

**After this session you’ll be able to:**

<!-- Learning Objectives Icon -->
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/learning_objectives.png" height = "90" width = "90" style ="display: inline-block"/>](#.)

## Learning Objectives

1. Describe the systems story your team believes will cause the outcomes you expect to observe in your experiment.  

2. Test your dynamic hypothesis about your team's clinical priority.  

3. Apply systems thinking to describe your team's findings, insights and conclusions from your experiment.

## Let's get started

## In-session Exercise (30 minutes): Comparing experiments 1 and 2

### Review Past Experiment

### 1. Log in to your individual or team world at mtl.how/sim.

### 2. Review your saved runs. Rename your saved runs if you feel you need to.

- Now is a time you can review your saved runs in the Experiment Maintenance section.

### 3. Review the data files you have uploaded for use and make sure you have what you want.

- You can also review the data files you have uploaded in the Team Data Menu Maintenance section.

### 4. You can Join Current Session or Start a New Session. If you Start a New Session select the team data file you’d like to use.

### 5. To refresh your memory and pick up where you left off last time, select the experiment from the last session and check the box to include text from this session in Expanded Outputs text fields. Review those text fields.

- What did we learn last time?

## **Plan for Experiment 2**

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_question.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Our Question.** *Briefly describe what your team wants to learn from this experiment.*

### 6. Study the systems story on the model diagram section and team data, and decide together what change you want to experiment with, that might give you the desired result.

- To think further about what to test next and a hypothesis about the outcomes, minimize the Outputs and Text section so you can see both that and the model diagram.

### 7. To create a new run building off of the previous one, revise the text in all the text boxes to reflect the experiment you want to do now.

- You can cut the text from the Our Decisions and move it to Our Question. Delete text in Our Findings. Now edit the team's question. It should clearly state a specific directional change in at least one variable over time. Ideally, the question will be framed as a comparison. For example, "As compared to Experiment 1 and the base case, could we increase/decrease ... over the next two years if we decide to..."  

- **CC** \- As compared to Experiment 1 and the base case, what will happen to the Starting Rate and New Patient Wait Time over the next two years, if we lengthen our team's average Return to Clinic Visit Interval (RVI), in units of weeks, by a certain amount?  
- **MM** \- As compared to Experiment 1 and the base case, how do we best allocate our x waiver appointments to serve 4 new OUD patients per week over the next two years?
- **PSY** \- As compared to Experiment 1 and the base case, what is the effect over the next two years of increasing the number of Initiators who Complete from the base case rate of 37% to 75% on the number of patients who complete and graduate?
- **AGG** \- As compared to Experiment 1 and the base case, if we lose two staff members in the near future, how are we going to change the proportion of appointments allotted to each service to ensure we can continue to meet patient needs over the next two years?
- **SP** \- As compared to Experiment 1 and the base case, what if we implemented stepped care between our clinic and PC/PCMHI?  How will patient flow and wait times change over the short- and long-term?

    [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_hypothesis.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Our Hypothesis.** *Outline the systems story your team believes will cause the outcomes your team expects to observe.*

- Now enter the team's hypothesis about the results. As we've discussed, research into experiential learning with simulation has shown that it is more impactful if the group “stakes a claim” before seeing the results of a scenario.  
- Ask, “What do you think the effects will be of simulating these new decisions?  How much better or worse will things get in the team over the next two years?”  Encourage the team to be specific about the **variables,** **specific values**, and to consider their decisions and the likely impact over time using the **causal systems story.**
- **Reveal complexities in the model diagram** to support the team telling the systems story supporting the causal relationship between the new decisions and the expected **system behavior over time.** Ask the team why this will happen. The hypothesis must track the effects of a **new decision** through the causal story of the **system problem,** following the causal arrows in the model diagram.
- Example: Reducing the Missed Appointment % will cause the amount of rework to decrease, and the total number of appointments on the calendar will drop.  This will free up provider time, and allow more hours to go toward starting new patients.  This in turn will add more patients to the team, and eventually the team will fill up all the extra slots, and the start rate will balance out at a new, but higher, rate than before.  

- **CC** \- Increasing the Return Visit Interval will have the effect of increasing the Appointment Supply for New CC Patients by decreasing the Appointments for Existing Patients. Just as in Experiment 1, the increased Appointment Supply for New CC Patients will increase the Starting Rate and decrease New Patient Wait Times. But decreasing the Appointments for Existing Patients will also lower the Completing Rate for CC patients.
- **MM** \- If we increase our proportion of appointments with an X waiver to 10%, then it will increase the starting rate.
- **PSY** \- We hypothesize that increasing the number of Initiators who complete from the base case rate of 37% to 75% will have a moderate increase in the number of patients who complete and graduate compared to the base case.  
- **AGG** \- Rebalancing the mix of patient services will provide additional capacity to serve patients, allowing the team to absorb the loss to two staff. We hypothesis that increasing the proportion of EB PSY to 20% and reducing PSY to just 5%, and then putting GROUP services at 15% and CC, MM, and ADJ all at 20%, would be appropriate for the team.
- **SP** \- With this change, clinicians in both settings will be more likely to step their patients between the two settings, as all the confusion and negotiation needed to step a patient between these settings will have been removed.  After implementing stepped care between our two settings, when one of our patients is low symptom, they will spend less time with our team before their provider feels comfortable recommending the patient step down to PC (see the arrow between "GMH and PC/PCMHI Implement Stepped Care" and "GMH to PC/PCMHI Engagement Time before Step down"), and for high symptom patients seen in the Primary Care setting, on average they will spend less time there before their provider recommends stepping up to General Mental Health. To see this causal connection, we must zoom in to that part of the process, by clicking on the plus sign in the grey "GMH Patients Waiting to Start" box.  We expect this smoother flow between the two settings to increase the number of openings for new patients in each setting, thus increasing the start rates and decreasing the number of patients waiting for both settings. Also, for Primary Care, they will be able to step more high symptom patients up to the right level of care sooner, so the number of patients in PC with a high risk flag will decline, as fewer high-symptom patients will remain in Primary Care for as long as before.  

## **Run Experiment 2**

### 8. Adjust experiment sliders for the new experiment, keeping in mind that the previous run’s settings are in effect.

- Drag the Text Section to the left so you can open the **Experiment Section.** _As you adjust sliders up/down in the Experiments section_, refine the text in the Hypothesis box to reflect the new practice decisions to be tested, _and the expected relative differences that will be observed as compared to the Base Case and Experiment 1._ Move each slider named in the question to its desired value.

### 9. Run and then Save (without resetting). Name this run according to the variable setting(s) you changed.

- To name the run, open the Variable drop-down menu, scroll to the first variable you changed and click *Add*. This will insert an abbreviation of that variable into the experiment name. Next highlight and Add the value you set that variable to. Do the same to add the next altered variable to the name. When you're finished, click *Save* (not Save & Reset, just Save). The date will automatically be added to the name of the saved experiment.

## **Compare Results**

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_findings.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Our Findings.** *Describe your team's findings, insights and conclusions from this experiment.*

### 10. Compare Runs to see the difference the between base case and the current experimental run.

- Prioritize review of _the expected relative differences as compared to the Base Case and Experiment 1._ in relation to the team's highest priority need. Expand the “Outputs” section to see the full Results Dashboard.  Charts for six key variables will be shown.  If other variables are needed, use the drop-down menu under any chart.
- Record your Findings. _As you review the model diagram_, type the findings and explanation into the “Our Findings” text box. Review how the systems story in Our Hypothesis explains or differs from the results of the simulated team decisions. Be specific about _how the relative quantitative impact of Experiment 2, as compared to Experiment 1 and the base case, is explained by the causal systems story._  

  - **CC** \- As compared to Experiment 1 and the base case, increasing the RVI increased the Appointment Supply for New CC Patients by decreasing the Appointments for Existing Patients. The increased Appointment Supply increased the Starting Rate for about 9 months and then it decreased. Same is true for New Patient Wait Times; a decline over time. But decreasing the Appointments for Existing Patients resulted in a sharp decrease in the Completing Rate for CC patients but it increased over time and reached a steady state at 1 year.  

  - **MM** \- Well, our fears are confirmed: as compared to Experiment 1 and the base case, if we increase the proportion of x-waiver slots to 10%, it does increase the starting rate for OUD MM to about 1 patient/month. But it also increased the wait times for patients with other needs.  

  - **PSY** \- Against the base case, we found that the total number of patients served by the team stayed the same (N=371). Of the 371, n=249 were Initiators and n=187 were Completers. Among Completers, n=7 graduated and were done. Regarding the starting rate for new patients, it decreased compared to our base case and our Experiment 1.  

  - **AGG** \- We found that keeping a tight RVI of just 1 to 2 weeks for PSY and EB PSY, further added capacity to manage our AGG service mix. All categories of patients in service ebbed downward over time as compared to Experiment 1 and the base case.  

  - **SP** \- When we open up the expanded outputs, [CHANGE FIRST CHART TO "GMH Patient Start Rate"] we can see that for General Mental Health, implementing stepped care did cause our start rate to increase from 12 to 16 pts/week as compared to Experiment 1 and the base case, then settle down at 13 per week; and the number of patients waiting to decrease, from 90 to about 60. However, we can also see two unintended consequences of implementing stepped care: 1) the ratio of high symptom patients to low increases, as it is easier to step low symptom patients down to Primary Care than before, and 2) the number of patients waiting to step down to Primary Care more than doubles, from 100 to over 215.  

- Let's look at the impact in PC to try to understand why wait times increase so dramatically.  [MINIMIZE THE EXPANDED OUTPUT WINDOW, AND CHANGE SETTING VIEW TO PC/PCMHI, AND CHANGE FIRST CHART TO "PC/PCMHI Patient Start Rate"]  We see that, like in General Mental Health, the start rate in Primary Care also increased, from ~6.5 to 8 pts/wk, settling at 7.5.  [CHANGE SECOND CHART TO "PC/PCMHI High Symptom Patients"] It looks like we were also right about the effect on high-risk patients in Primary Care: they are able to reduce both the number of high-symptom patients in their care, and the number of patients with a high risk flag. Even with the increase in the Recommend Step Up Rate, the number of patients waiting to step up to GMH falls. From this view, too, though, we see the increase in patients waiting to start PC, which we know are mostly coming from General Mental Health.
- Why is this happening? Even though the effect on flow between the two settings was the same (i.e., implementing stepped care reduced the Time to Recommend in both settings by 50%), the size of the two settings is not. [MINIMIZE THE EXPANDED OUTPUTS, OPEN EXPERIMENTS, CLICK ON BASE CASE VALUE FOR "PC/PCMHI Manageable Total Patients"] We know that GMH can maintain over 500 patients in treatment, but Primary Care can only maintain about 300 mental health patients. Implementing Stepped Care between these two settings with a substantial size difference means more patients trying to flow from General to Primary Care than from Primary Care to General. Even though both settings are trying to step more patients out to a more appropriate level of care, the increase in openings in Primary Care is not enough to accommodate the increase in demand from General to step patients down into Primary Care. Thus, the resulting average wait time to step down from GMH to PC practically doubles over the next two years.  

    \[CLICK BACK TO GMH EXPANDED OUTPUTS TO FINISH TYPING TEXT\]

  [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_decisions.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Our Decisions.** *Based on what you learned in this experiment, what changes are you ready to make in your practice?*  

### 11. Discuss and record what changes you may want to make in the clinic and what further experiments you want to run.

- Discuss what **new decisions** the team wants to test next. Ideally, the **highest leverage** and **most feasible (i.e., decisions that individual and the team have under their control)** experiments were tested in session 8 (Experiment 1) and session 9 (Experiment 2).
- Therefore, _to apply systems thinking_ in session 10, ask the team to consider a combination of experiments 1 and 2.  Ask the team to type in the Decisions box, _both_ 1) what they would like to experiment with next, and 2) any _new decisions they may make in their clinical practice based on what they learned._  

- **CC** \- We decided to try a combination of experiments 1 and 2. We will experiment with both increasing our overall Appointment Supply in care coordination and increasing our targeted Return Visit Interval for existing patients. As I meet with more stable patients, I will consider who may appropriately have a longer RVI, which may free me to see more new patients, and increase overall scheduling flexibility for all my patients.

- **MM** \- This tradeoff is not a good one for the team. Increasing referrals and reallocating appointments is not enough to serve the new OUD patients without an impact on our other patients. We will use the simulation to identify more optimized practice decisions.

- **PSY** \- We will run a third experiment. We will look to see if we can combine the effects of graduating 75% of all Completers AND increasing Initiators who Complete. We need the appointment supply that becomes available by keeping to a higher graduation rate of Completers to accommodate the higher number of Initiators who are transitioned to Completers!

**AGG** \- We will explore sensitivity to work pressure in our next experiment, but keep our new service mix and our improved RVI for PSY and Evidence-based Psychotherapy. I can begin to shift some of my referral and RVI decisions now.

**SP** \- With this experiment, we have seen the impacts of increasing coordination and efficiency in stepping patients between settings, but without increasing quality of care. Next, let’s conduct a combined experiment, where we implement both measurement-based care and streamline stepping between GMH and PC/PCMHI. I can begin to collect standardized measures from more patients to guide my care decisions in our team, and between my team and other teams in our clinic.

### 12. Save and Reset when ready.

- *Don't forget to log off the sim UI.*

## That's it for *Modeling to Learn* how to compare alternatives. Next is our Done/Do review.

## Done and Do (15 minutes)

<!-- Do/Done Tables -->
| [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/done.png" height = "80" width = "80">](#.) **Done** | [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/do.png" height = "90" width = "90">](#.) **Do** |
| --- | --- |
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) Today we ran experiment 2 and used the Control Panel in the Outputs and Text section to compare base case, experiment 1 and experiment 2 results.  | [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) Run a third experiment in your individual world. |

## DO Demo

1. If you can, run a third experiment in your Individual world. You might consider one that combines the decisions of your Experiment 1 and Experiment 2.
2. To do this, log back into the SIM UI. In Experiments, select your Experiment 2 run from the list of saved experiments. Click GO and select the box to include text, to reload your prior QUESTION, HYPOTHESIS, FINDINGS and DECISIONS.
3. Expand the OUTPUTS AND TEXT section to reveal all the text and results saved from the run. Use these to refine and document your Question and Hypothesis for Experiment 3.
4. When you set the sliders for this experiment, remember that they are starting out set as you had them for Experiment 2. Run the simulation and note your Findings and Decisions.
5. As always, save your work and log off.

**Until next time, thank you for *Modeling to Learn*!**
