---
title: "MTL Session 8 - Facilitator Say"
author: "Team PSD"
date: "May 2022"
release: "MTL 3.0"
output: 
  github_document: default
  html_document: default
  pdf_document: default
  word_document: default
  ioslides_presentation: default
  slidy_presentation: default
  powerpoint_presentation: default
---

[<img src = "https://github.com/lzim/teampsd/blob/master/resources/title_slides/mtl_s08_dynamic_hypothesis_title.png"
     height = "175" width = "420">](#DontLink)  

# MTL Live Session 08

## Today we're modeling to learn how to test a dynamic hypothesis.

Hello! I'm \________________ (facilitator's name) and I'm \_______________ (co-facilitator's name). Today we're modeling to learn how to test a dynamic hypothesis.

**As you can see in the Done/Do table at the top of the Learner See Guide:**

## Done and Do (15 minutes)

<!-- Do/Done Tables -->
| [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/done.png" height = "80" width = "80">](#.) **Done** | [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/do.png" height = "90" width = "90">](#.) **Do** |
| --- | --- |
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim)  We logged in to mtl.how/sim and explored the results of the base case (bc) run in the Results Dashboard of the Outputs and Text section to prepare for experiment 1. | [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We will test a dynamic hypothesis about ___________ by running experiment 1 and comparing results against the bc.

**After this MTL session, you will be able to:**

<!-- Learning Objectives Icon -->
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/learning_objectives.png" height = "90" width = "90" style ="display: inline-block"/>](#.)

## Learning Objectives

1. Describe the systems story your team believes will cause the outcomes you expect to observe in your experiment.
2. Test your dynamic hypothesis about your team's clinical priority.
3. Apply systems thinking to describe your team's findings, insights, and conclusions from your experiment.

[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:05-00:10

### Let's get started! Who wants to drive today?

## In-session Exercise (30 minutes)

## Running an experiment

**Providers know there are a lot of interdependencies that make improving care in the clinic challenging. Often, because we’re embedded in such a large care system, we may be “flying blind” with regard to how our own care decisions fit within all that is going on locally. We can use simulation to help reveal the connections and figure out which changes work, which don't, and which are sustainable, a lot faster and safer than in the real world.**

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:10-00:15 | **Cue** up last time q/h/f/d |

### 1. Log in to your individual or team world at mtl.how/sim.

### If you logged into your individual world, review your saved runs in the Experiment Maintenance section. Rename your saved runs if you feel you need to.

- On the *MTL* Home page, you will see the "Experiment Maintenance" section in the middle. This is where you can review your saved runs by clicking the blue bar to expand the section.  
- Here, you are able to *Delete*, *Rename*, or *Export* your experiments.
- A team may need to rename experiments if they want to be sure they are able to differentiate between experiments or if they incorrectly named a file in a prior session. If you need to rename any of your saved runs, check the box to the left of the file name, click Rename*, change the name, and Save.

### If you logged into your individual world, review the data files you have uploaded in the Team Data Dropdown Maintenance section and make sure you have the data file you want.

- The section on the right side of the *MTL* Home page is "Team Data Menu Maintenance". This lets you alter what you see in the drop-down menu for selecting a Team Data file when you want to Start a New Session (in the Session section). You can *Delete*, *Rename*, or *Add* data files. You would not want to rename a Team Data file unless you did not already have it entered exactly as it is named at mtl.how/data.

### You can Join Current Session or Start a New Session in any module. If you Start a New Session select the team data file you’d like to use.

- If you *Start a New Session* you will need to select the team data file you would like to use for this session. Click the "Select Team Data" icon. A pop-up box will appear that says, "Please select a model input file." Click to open the drop-down menu and choose the data file you would like to use.

### To refresh your memory and pick up where you left off last time, select the experiment from the last session and check the box to include text from this session in Expanded Outputs Text fields. Review those text fields.

- You will see the main, model diagram section, the *Outputs and Text* section, and the *Experiments* section, with a smaller, floating *Text* section. You can drag that section over or "X out" of it to make room to open the *Experiments* section. To pick up where we left off last time, expand the *Experiments* section by clicking on the blue bar. At the top you will see, "Select Previous Experiment to Set Experimental Values to a Former State."  

    Time Stamp | Prioritize tailored team learning | Script
    -- | -- | --
    [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:15-00:20 | **Review** the team data the led to that q/h/f/d | **1. Practice highlighting specific values from the Team Data table that are guiding the in-session work to address the team's highest priority need.**  

- Open the drop-down menu for Select Experiment and select the base case experiment from the last session.
- When you click the red "Go" button, a pop-up box will appear that says "Review Previous Settings." Because you've selected the base case experiment, all of the values showing in the Experimental Values box should show either bc or 0 (or 1 for sensitivities).
- You will also want to check the box to "Include text from this session in Expanded Outputs text fields".
- As a reminder, the text fields are: Our Question, Our Hypothesis, Our Findings, Our Decisions. To bring up the text boxes for easy review, click on the Outputs and Text bar. Click to Expand. Click on the layered squares or windows in the upper right corner of the blue bar to make the text box smaller so it's easy to review the text in the text boxes and main model diagram.  

    Time Stamp | Prioritize tailored team learning | Script
    -- | -- | --
    [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:20-00:25 | **Review** the relevant causal system story | **2. Practice describing the Reveal Dynamics Over Time (causal loop) most relevant to the team's highest priority need.**

### Study the system diagram and team data, and decide together what change you want to experiment with, that might give the team the desired result.
  
- Click on \_\_\_\_\_\_\_\_\_\_\_\_ under "Reveal Dynamics Over Time" to see the systems story relevant to the experiment you decided on in the last session.
- In the diagram, the rectangles that look like the levels of gas that you have in your gas tank are showing states in care where patients or appointments can accumulate or drop. For example, in this team we see \_\_\_ patients in the \_\_\_\_\_\_\_\_ stock.  The number of patients in a state are influenced by flow rates - designated by circles here that look like speedometers. For example, this \_\_\_\_\_\_ rate shows that about \_\_\_ patients per week in this team move from \_\_\_\_\_\_\_\_\_ to \_\_\_\_\_\_\_\_\_ \[show with mouse work\].  

- **Example:**
  - **First, explore the Appointments section of the diagram and see how Appointment Supply links to a number of variables.**
  - **Then, examine the Patients section and notice how the different gauges and rectangles are linked and what causes them to increase or decrease.**
  - **Finally see how the Patients and Appointments interact with each other, for example, by examining appointment supply and return visit interval. Remember, red means values that are read into the model from your team data.**
  - **As a team, you decide what change to experiment with in the sim. To make that decision, you should ask: 1) How do we think things will change over time if make a specific change?; and 2) What relationships in the system will interact if we make that change? Ultimately, the team should choose changes that might give the desired result, based on the team vision and team need.**  

    Time Stamp | Prioritize tailored team learning | Script
    -- | -- | --
    [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:25-00:35 | **Adjust** sliders and set up team's dynamic hypothesis | **3. Practice describing specific value adjustments you expect will be helpful for the team to experiment with related to their highest priority need.**

### 2. To create a new run building off of the previous one, revise the text in all the text boxes to reflect the experiment you want to do now.

- Let's create a new experiment building off of the previous one, the base case of no new decisions. The important thing for learning is to stake a claim about your expectations, so the simulation output can teach you something. This process can also help teams to reconcile differences and achieve consensus about ways to move forward and take action for improvement. You all probably won't agree about what the likely impact of any change will be, but we can use Modeling to Learn engage in participatory learning to find out.
- The first step is to revise the text in all the text boxes to reflect the experiment you want to do now:  

    [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_question.png" height = "50" width = "50" style = "display: inline-block"/>](#.) [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_hypothesis.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Example Questions and Hypotheses:** *Briefly describe what your team wants to learn from this experiment and outline the systems story your team believes will cause the outcomes your team expects to observe.*

- **CC**
  - Q: What will happen to the Starting Rate and New Patient Wait Time if we increase the Appointment Supply of care coordination appointments overall?
  - H: Increasing the CC Appointment Supply will make more Appointments available for both new and existing CC patients. The Additional Appointment Supply for New CC Patients will increase the Starting Rate and lower New Patient Wait Times.  

- **MM**
  - Q: How could we serve more patients with specific conditions, like OUD, with our existing staffing levels?
  - H: If our referral rate for OUD is 2 pts per month (0.5 per week), and we allocate 40% of our x-waiver slots to OUD treatment, and 40% to Other Needs, and we change our RVI for depression to 12 weeks, and the RVI for OUD to 4 weeks (in line with our quality standards), then we will serve more OUD patients with our existing team staff, without increasing the wait time for new depression patients.  

- **PSY**
  - Q: What if we graduate more patients who complete 8 or more psychotherapy sessions in their first 3 months? What is the effect of working to increase the proportion of patients who 'complete' an evidence-based dose of PSY and then graduate from just 4% to 75%, over time, on (1) the number of patients who complete and are then 'done'? and (2) on the supply of available appts for new patients?
  - H: We expect that if we increase our completers who graduate to 75%, then we'll free up more slots in the clinic for more patients to start psychotherapy/EBPsy. We hypothesize that increasing the complete and graduate rate from 4% to 75% will result in a jump from about 4 patients to about 75 patients graduating during the same time period. We also expect that by increasing the graduation rate for any one who has received 8 or more sessions of PSY, we will increase the number of appt slots for new patients starting PSY.  

- **AGG**
  - Q: How can we manage the loss of two providers and still manage patient needs for PSY? What would happen if we change the PSY RVI to 2 weeks and the RVI for EB PSY to just 1 week (from 17 weeks)?
  - H: We expect to see the number of PSY patients in service to go down within the first year, and then to reach a new level that is well below 300. If the numbers were down to 150 patients, then we may be able to handle the staff reduction.

- **SP**
  - Q: How much does implementing Measurement Based Care improve our ability to get our high symptom patients into the right care at the right time? How will this change in our team impact the other settings in Mental Health?   Will it kick off a virtuous cycle of GMH care quality improving recovery?
  - H: If we more readily detect patients' symptoms and risk, then our improvement rate will increase, moving more patients in to recovery. For this team, with their local resources and constraints, can more patients graduate from general mental health care, our patient load will drop and open more slots to start new care episodes. If we implement measurement based care in our GMH team, then care quality will improve (specifically through reductions in Time to Improve and Time to UnFlag, and an increase in the Time to Ending). Also, how long it takes clinicians to see changes in their patients will also improve (seen in a reduction in Time to Detect). We expect to be able to effectively diagnose and treat patients faster, reducing the number of high-symptom patients in care, and thus reducing the number of patients who receive high risk flags.  However, low symptom patients are in care for longer than before, reducing the number of openings for new patients. These patients will make up more and more of our total – as there will be both more flowing in (due to higher Improvement Rate) and fewer flowing out (due to the lower Ending Rate). With fewer openings, wait times to start with our team should increase.

### 3. Adjust experiment sliders for the new experiment, keeping in mind that the previous run’s settings are in effect (for this session that just means the base case or default values).

- Slide the Text box to the left, over the model section. This will allow you to adjust experiment sliders for the new experiment.
- In the experiments section we also have experimental sliders with “i” information that tells you what you’re changing when you adjust that slider in your experiment.
- Keep in mind that the previous run’s settings are in effect -- in this case, we have only run the bc or base case so the default values from the team data are the previous run settings.
- A quick tip -- make note of the service or services you selected to change and the new values, that is, what you changed the numbers to, so you have that information available for naming the experiment when you save it.  

    Time Stamp | Prioritize tailored team learning | Script
    -- | -- | --
    [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:35-00:40  | **Run** experiment

### Run and then Save (without resetting).  Name this run according to the variable setting(s) you changed.

- To name the run, click on the down arrow next to Variable, choose the variable you changed, for example, Appointment Supply or Return Visit Interval. Click *Add*. This will insert an abbreviation of that variable into the experiment name.
- Click on the down arrow next to Service, choose the service you adjusted, for example, Psy, Medication Management or Adjunctive services. Click *Add*.
- Finally, click on the down arrow next to Number, choose the number that represents the new value you used in your experiment.
- Click *Save* (not Save & Reset, just Save). The date will automatically be added to the name of the saved experiment.  

    Time Stamp | Prioritize tailored team learning | Script
    -- | -- | --
    [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:40-00:50 | **Describe** findings/decisions and save | **4. Practice describing outputs (system behaviors) you're going to check and discuss as a team in relation to the team's highest priority need.**

### 4. Compare Experiments to see the difference the between base case and the current experimental run.

- Navigate to the Results Dashboard. It is here you can choose up to two prior experiments' results to compare with the current run. Select your base case run.  
- There are six charts in the dashboard at a time. To see the default set of charts for a specific service, cohort, or setting, go to the main model diagram Experiment Timeline box and under "Display Patient Services" click on the service, cohort, or setting for the specific charts you want to review.  First, let's look at \_______ chart, in the \_________ section of the screen, as it answers our question \_________ .
- To see charts of other variables, click on the down arrows under any chart to bring up a list of all variables.
- **Examine the differences between the base case and the current experimental run. How do these results compare against your hypothesis?**
- **As you describe the findings, record what you observe and learn in the *Our Findings* text box:**  

  \_\_\_Example of chart review for SP:\_\_\_  
  
- In our last session, based on the team’s needs assessment, we focused on the team’s issue with long wait times stepping patients up from GMH to SMH when needed. In the bottom middle panel we can see that implementing MBC in our GMH team is likely to reduce the wait Time to Step up to SMH from approximately 45 weeks to 32 weeks over the next two years. I’ll use my mouse and click the down arrow to show you the full variable name, which is highlighted in blue. This reduction in wait times for stepping patients up to Specialty Mental Health is due to the reduction in high symptom patients over the next two years.
- We can see this by looking at the upper middle and upper right panels, which show how implementing MBC will improve GMH care quality: As the improvement rate increases, the ratio of high to low symptom patient decreases, fewer patients receive a high risk flag and wait times to step up to SMH decrease.
- However, looking at the graph in the upper left corner, patient load stays the same in our MBC experiment as it was in the base case -- something prevents our virtuous cycle. The virtuous cycle of our reinforcing feedback, “Higher care quality improves recovery,” depends on the team getting patients better and moving them on from GMH.
- As result of our experiment, although wait times to step up form GMH to SMH go down, the lower left and right graphs show that wait times to step down to PC/PCMHI increase, and GMH patients waiting to start increases over the next two years.
- To summarize, yes, more of our patients are stabilizing and able to be stepped down to PC. But, we aren't stepping them all down to PC because PC hasn’t made any new decisions in this experiment and hasn’t implemented any strategies to take on our patients. This causes longer wait times to step GMH patients down, which further reduces the number of patients the GMH team will recommend should step down for care. As we can see in the bottom left graph, the black line for our current MBC experiment shows that improvements in GMH quality due to implementing Measurement Based Care without coordinating this change with primary care will lead to increased wait-times for stepped down, and lead to the undesirable effect of patients waiting to start care in GMH as our stabilized patients build up in our GMH clinic.
- Thus, low symptom patients build up in our clinics. Also, PC is taking more patients than they can handle, so their quality declines, and GMH gets more patients stepping up from PC --> demand for GMH goes up!  Something that we think is outside of our control is actually a result of our own decision.  

    [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_findings.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Example Findings:** *Describe your team's findings, insights and conclusions from this experiment.*  

- **CC** \- Increasing the supply of Appointment Supply for New CC Patients does increase the new CC patient weekly Starting Rate, which reduces new CC patients Waiting to Start.  

- **MM** \- We found that if we allocate 50% of our x-waiver provider appointments to OUD, in the long run instead of only starting ½ patient per week (1 every other week), we can start 3 patients in OUD per week. But dropping the appointment supply for our *Other* patients meant we could not start any of them in care for a while until some existing patients completed and moved on. A backlog built up, which caused referrals to slow. When we were eventually able to start *Other* patients, the backlog dropped so referrals picked up again, and we established a new steady state with about 15 *Other* diagnosis patients waiting to start and about 170 in care.  

- **PSY** \- We found that the total number of patients served by the team increased from N=371 to N=460. Of the 460, n=358 were Initiators and n=132 were Completers. Among Completers, n=99 graduated and were done (75%, as we expected). Regarding the starting rate for new patients, it increased from about 3.8 pts/wk to about 4.8 pts/wk. our hypotheses was supported. This dramatically increases the number of patients in PSY who are receiving an evidence base dose of therapy and supports the team in taking on more new patients, about one more new pt/wk (or 4 new ones per month, or 48 new ones annually!).  

- **AGG** \- Our hypothesis was supported! We see that implementing a much shorter RVI for PSY patients show a steady reduction in the number of PSY patients in service, from more than 300 in our bc to less than a 100 after two years. Booking rates for PSY climb initially, but then drop off and level out just a bit higher than baseline! One concern is that MM patients in service also drops from about 1000 to 900.  

- **SP** \- As predicted, we see a dramatic shift in patient from “high symptom” to “low symptom,” as both detection and care quality improve – the ratio of high to low symptom patients drops from 0.6:1 to 0.2:1 over two years. The number of patients with a suicide flag decreases by more than 50%, as more high symptom patients have their symptoms addressed before they can be flagged in the first place. However, the initial predicted reduction in Ending Rate is off-set by long-term increases in the Recommend Step Down Rate, thus not permanently impacting the new patient start rate. Both new patient starts and wait times in our clinic increase in the short-term, but fall below our historical average by 3 months, and continue to fall for the next year. However, because there have been no changes in Primary Care, the number of patients waiting to step down to PC hs increased substantially – from about 110 to 170, who are all undoubtedly waiting significantly longer than before.

### 5. Discuss and record what changes you may want to make in the clinic and what further experiments you want to run.

- Based on what you saw here, and what further experiments you want to run in the Sim.
- Type those into the *Our Decision* text box.  

     [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_decisions.png" height = "50" width = "50" style = "display: inline-block"/>](#.) **Example Decisions:** *Based on what you learned in this experiment, what changes are you ready to make in your practice?*  

- **CC** \- Next time we will experiment with adjusting our Return Visit Interval.  

- **MM** \- Although we were glad to see that we could care for more OUD patients with our available staffing, we are concerned that if all we do is shift several of our Other appointments to OUD, we won't be able to help as many Other patients. We decided to experiment with Return to Clinic Visit Intervals as a possible alternate solution.  

- **PSY** \- For our next experiment, since we have now affirmed that we have additional appt capacity for new (and existing patients), we would like to explore how changing Initiators who Complete from the base case rate of 37% to 75% might impact the number of patients who complete and graduate. This will be the only change we make, so that we can see the effect clearly.  

- **AGG** \- Now that we have reduced the RVI for PSY and EB PSY, we can look to see what gains in managing our patients may be achieved by rebalancing our service mix. We'll see what happens if we invest in doing more EB PSY and less PSY, but keeping the proportion of other services more or less as before.  

- **SP** \- In this experiment, we see a strong connection between changes made in our team and demand and wait times for downstream teams. We should run an experiment that explores these connections, specifically to gauge the impacts of implementing stepped care between GMH and PC/PCMHI.  

**In an interconnected system, with causal interdependencies over time, simulation can help us find out when our short-term decisions are going to make things worse in the longer term.  In the real world, it would be very hard to perceive these longer term system effects, but we can see them using *Modeling to Learn* and we can evaluate the results against other available decisions to compare their effects and better coordinate Veterans' care across the team to increase care quality [expand access, or reduce symptoms and risk].**

### Save and Reset when ready.

- Log out of the SIM UI.

### That's it for _Modeling to Learn_ how to test a dynamic hypothesis. Next is our Done/Do review.

## Done and Do (15 minutes)

<!-- Do/Done Tables -->
| [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/done.png" height = "80" width = "80">](#.) **Done** | [<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/do.png" height = "90" width = "90">](#.) **Do** |
| --- | --- |
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We ran experiment 1 and compared results against the bc. | [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) Explore the bc and experiment 1, and draft a dynamic hypothesis to prepare for experiment 2. |

## Until next time, thank you for *Modeling to Learn*!

Time Stamp | Prioritize tailored team learning | Script
-- | -- | --
[<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/timestamp.png" height = "40" width = "40" style ="display: inline-block"/>](#.) 00:50-00:60 | **Success** - A successful Done/Do Review is short, specific, simple and shown.

## DO Demo

1. Before next time, please explore the base case and experiment results and draft a dynamic hypothesis to prepare for experiment 2.
2. To do this, log back into the SIM UI team world.
3. In Experiments, select your Experiment 1 run from the list of saved experiments. Click on GO and select the box to include text, to reload your prior QUESTION, HYPOTHESIS, FINDINGS and DECISIONS.
4. Expand the OUTPUTS and TEXT section (two clicks!) to reveal all the information saved from the run.
5. Copy, paste, and edit your Decisions text to begin developing your new Question and Hypothesis for Experiment 2.
6. Save your work (do not Reset) and log off.
